{"cells":[{"cell_type":"markdown","id":"5bae176e","metadata":{"editable":true,"tags":[],"id":"5bae176e"},"source":["# Computer Vision\n","\n","[![How we teach computers to understand pictures](https://storage.googleapis.com/rg-ai-bootcamp/cnn/computer-vision-leo.png)](https://www.youtube.com/watch?v=40riCqvRoMs)\n","\n","Source: [TED Talk](https://www.youtube.com/watch?v=40riCqvRoMs)\n","\n","Computers are very good at being consistent and processing numbers. But they're blind, sure they can show images for us in our monitor, but it cannot directly interact with us like human-to-human interaction. Like giving us feedback or help us monitor our CCTV feed and let us know if something is suspicious. That's because until the recent age of AI, computers are blind. There are attempts to emulate vision, which is what the field Computer Vision is. Let's start with how we see the world.\n","\n","## How humans see the world\n","Have you ever think about what's happening when we see with our eyes ? Look around and what do you see ? A chair, a table, a computer, a smartphone and many others. How do we know that object is indeed a chair or A table ?\n","\n","If we think about it, back when we were younger, our parents or other people would point out an object and call out it's name. Sometimes it's explicit, for example \"that's a green apple\". Sometimes it's implicit, \"let's sit at the chair over there\". We will then observe the object, take notes and give it an appropriate label. So we identify an object and give it a label.\n","\n","## How do computers see the world ?\n","\n","The story began back in 1959 where a group of neurophysiologists showed a cat an array of images, attempting to correlate a response in its brain. They discovered that it responded first to hard edges or lines, and scientifically, this meant that image processing starts with simple shapes like straight or curved edges, not objects. Interesting isn't it ?"]},{"cell_type":"markdown","id":"9c6561c1","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"9c6561c1"},"source":["## How Computer Vision works\n","\n","Which one is correct ? Well, apparently both of them, the field of computer vision does follow how our brain works, so we also start with the edges before the object, but it's happening so fast that we don't even think about it anymore.\n","\n","In any case, we are not going to discuss how our brain works in relation to computers, we are here to learn about the application of computer vision to enable computers to see.\n","\n","Two essential technologies are used to accomplish this:\n","- A type of machine learning called deep learning, which we already covered earlier\n","- A convolutional neural network (CNN), which we are going to learn next"]},{"cell_type":"markdown","id":"cf362802","metadata":{"id":"cf362802"},"source":["# Convolutional Neural Network (CNN)\n","\n","A Convolutional Neural Network (CNN) is a type of artificial neural network (ANN), that was designed for image recognition using a special type of layer, aptly named a convolutional layer, and has proven very effective to learn from image and image-like data. Regarding image data, CNNs can be used for many different computer vision tasks, such as image processing, classification, segmentation, and object detection.\n","\n","In total, there are three main types of CNN layers:\n","\n","- Convolutional layer\n","- Pooling layer\n","- Fully-connected (FC) layer\n","\n","![CNN Layers](https://storage.googleapis.com/rg-ai-bootcamp/cnn/convnet-layers.png)\n","\n","Source: [Research Gate](https://www.researchgate.net/figure/Simple-Model-of-Convolutional-Neural-Network_fig2_344622537)\n","\n","From the picture above, the input image goes through the convolution process in the convolution layer and the output is a feature map. The feature map then went through subsampling in the Pooling layer (subsampling layer) which effectively reduces the size by half, and so on, until it reaches the final layer which is a fully connected layer where the input is processed to return a probability between 0 and 1. With each layer, the CNN increases in its complexity, identifying greater portions of the image. Earlier layers focus on simple features, such as colors and edges. As the image data progresses through the layers of the CNN, it starts to recognize larger elements or shapes of the object until it finally identifies the intended object.\n","\n","> Note: ANN is actually the same Neural Network that we learn earlier, so we'll use the term Neural Network or NN going forward."]},{"cell_type":"markdown","id":"c9cc0ac5","metadata":{"id":"c9cc0ac5"},"source":["## Application of Computer Vision"]},{"cell_type":"markdown","id":"cff44756","metadata":{"id":"cff44756"},"source":["Source: [AI Index Stanford](https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report-2023_CHAPTER_2.pdf)"]},{"cell_type":"markdown","id":"fef864a5","metadata":{"id":"fef864a5"},"source":["![](https://storage.googleapis.com/rg-ai-bootcamp/cnn/face-detection.png)"]},{"cell_type":"markdown","id":"b8497dee","metadata":{"id":"b8497dee"},"source":["![Pose Estimation](https://storage.googleapis.com/rg-ai-bootcamp/cnn/human-pose-estimation.png)"]},{"cell_type":"markdown","id":"4204e077","metadata":{"id":"4204e077"},"source":["![semantic-segmentation](https://storage.googleapis.com/rg-ai-bootcamp/cnn/semantic-segmentation.png)"]},{"cell_type":"markdown","id":"b0741311","metadata":{"id":"b0741311"},"source":["![medical-image-segmentation](https://storage.googleapis.com/rg-ai-bootcamp/cnn/medical-image-segmentation.png)"]},{"cell_type":"markdown","id":"bdcc5c75","metadata":{"id":"bdcc5c75"},"source":["![object-detection](https://storage.googleapis.com/rg-ai-bootcamp/cnn/object-detection.png)"]},{"cell_type":"markdown","id":"7f316877","metadata":{"id":"7f316877"},"source":["![which-face-is-real](https://storage.googleapis.com/rg-ai-bootcamp/cnn/which-face-is-real.png)"]},{"cell_type":"markdown","id":"e9b59acd","metadata":{"id":"e9b59acd"},"source":["Source: [MIT 6.S191: Convolutional Neural Networks](https://www.youtube.com/watch?v=NmLK_WQBxB4)"]},{"cell_type":"markdown","id":"d4b487f3","metadata":{"id":"d4b487f3"},"source":["![self-driving-car](https://storage.googleapis.com/rg-ai-bootcamp/cnn/self-driving-car.png)"]}],"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[{"file_id":"1nnPnjcGK1-qt1-T4sc0twZ9LlghW3ELt","timestamp":1707451292685}]}},"nbformat":4,"nbformat_minor":5}