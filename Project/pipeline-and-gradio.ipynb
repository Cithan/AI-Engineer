{"cells":[{"cell_type":"markdown","metadata":{"id":"VFa5VyVNPCJY"},"source":["# Project: Image Classification using Pipeline dan Gradio"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"BjLC0KyJgSRg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Qg7V4zoPCJi"},"source":["**Description:**\n","\n","Welcome to your new assignment! In this project, you will have the opportunity to apply the knowledge and skills you've learned in class. The task at hand is to create an image classification project that predicts a person's age based on their photograph. You will be utilizing the power of machine learning pipelines to streamline your workflow and effectively manage the different stages of this project, from data preprocessing to model training and evaluation.\n","\n","Remember, the goal of this assignment is not just to build a model that makes accurate predictions, but also to understand the process of developing a machine-learning pipeline and the role each component plays in this process.\n","\n","We encourage you to be creative, explore different strategies, and most importantly, have fun while learning. We can't wait to see the innovative solutions you come up with! Best of luck!"]},{"cell_type":"markdown","metadata":{"id":"ZysTKHbGioh8"},"source":["## Student Identity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8BlcSWzioi3"},"outputs":[],"source":["# @title #### Student Identity\n","student_id = \"REA110FJ\" # @param {type:\"string\"}\n","name = \"Citra Handan\" # @param {type:\"string\"}\n","drive_link = \"https://colab.research.google.com/drive/1qNV8wbPeeaoHfvkmdLR0-pcpw98xaT9g\"  # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"vJWjH2kGV49k"},"source":["## Installation and Import Package"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wWESOr0PCJk","executionInfo":{"status":"ok","timestamp":1707118355843,"user_tz":-420,"elapsed":40742,"user":{"displayName":"Citra Handan","userId":"02659360695432655610"}},"outputId":"86b968ae-bce4-496f-caff-a2e78a2df95c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rggrader in /usr/local/lib/python3.10/dist-packages (0.1.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from rggrader) (2.31.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from rggrader) (1.5.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rggrader) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (1.23.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (2023.11.17)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->rggrader) (1.16.0)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.16.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.2)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n","Requirement already satisfied: gradio-client==0.8.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.0)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.7)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.0)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0.post1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (2023.6.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (11.0.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.1)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n","Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.36.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n","Requirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2023.11.17)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["# Install necessary packages\n","\n","!pip install rggrader\n","from rggrader import submit, submit_image\n","\n","# Put your code here:\n","!pip install gradio\n","!pip install huggingface\n","!pip install huggingface-hub\n","!pip install transformers\n","\n","import requests\n","from io import BytesIO\n","\n","from PIL import Image\n","\n","from transformers import ViTFeatureExtractor, ViTForImageClassification\n","\n","\n","# ---- End of your code ----"]},{"cell_type":"code","source":["import gradio as gr"],"metadata":{"id":"CRolA-g6SokV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_mbLFq9Vvcg"},"source":["## Pipeline"]},{"cell_type":"markdown","metadata":{"id":"Io4CCbvZ-220"},"source":["**Task 1: Image Classification using Hugging Face's Model**\n","\n","In this first task, your task is to develop an image classification pipeline that takes **an image URL as input**, displays the image, and uses the Hugging Face's model to predict the age of the person in the image. You can get the model [here](https://huggingface.co/nateraw/vit-age-classifier).\n","\n","Here are the key steps that you might be able to follow:\n","\n","1. **Image URL Input:** Your program should accept an image URL as input. Make sure to handle potential issues with invalid URLs or inaccessible images.\n","2. **Image Display:** Display the image from the URL in your notebook. This will provide a visual confirmation that the correct image is being processed.\n","3. **Model Loading and Prediction:** Load the 'nateraw/vit-age-classifier' model from Hugging Face's model hub and pass the image URL to the model to obtain the prediction. The model should predict the age of the person in the image.\n","4. **Output Display:** Display the output from the model in a clear and understandable manner.\n","\n","## Submission\n","\n","- What percentage is the person in this picture (https://images.unsplash.com/photo-1596392927852-2a18c336fb78?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1280&q=80) is between age of \"3-9\"?\n","\n","Submit in the numeric format up to 5 digits behind the decimal point. For example in below output:\n","\n","```\n","{'0-2': '0.00152',\n"," '3-9': '0.00105',\n"," '10-19': '0.02567',\n"," '20-29': '3.32545',\n"," '30-39': '51.75200',\n"," '40-49': '40.24234',\n"," '50-59': '4.47803',\n"," '60-69': '0.17092',\n"," 'more than 70': '0.00304'}\n","```\n","\n","The answer would be `0.00105`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5LA1LcdPCJm","executionInfo":{"status":"ok","timestamp":1707118709965,"user_tz":-420,"elapsed":5078,"user":{"displayName":"Citra Handan","userId":"02659360695432655610"}},"outputId":"5752009e-1be4-4186-f4d7-02cba8e08589","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0.81005\n"]}],"source":["# @title #### 01. Image Classification using Hugging Face's Model\n","\n","# Put your code here:\n","r = requests.get(\n","    'https://images.unsplash.com/photo-1596392927852-2a18c336fb78?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1280&q=80')\n","im = Image.open(BytesIO(r.content))\n","\n","model = ViTForImageClassification.from_pretrained('nateraw/vit-age-classifier', cache_dir=r\"./checkpoint\")\n","transforms = ViTFeatureExtractor.from_pretrained('nateraw/vit-age-classifier', cache_dir=r\"./checkpoint\")\n","\n","inputs = transforms(im, return_tensors='pt')\n","output = model(**inputs)\n","\n","proba = output.logits.softmax(1)\n","\n","result = round(proba.tolist()[0][proba.argmax(1)], 5)\n","print(result)\n","# ---- End of your code ----\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"La_Uvs29-221","executionInfo":{"status":"ok","timestamp":1707119050449,"user_tz":-420,"elapsed":737,"user":{"displayName":"Citra Handan","userId":"02659360695432655610"}},"outputId":"f257c9ba-3fbd-470a-ae2e-b7369375685e","colab":{"base_uri":"https://localhost:8080/","height":36}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Assignment successfully submitted'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["# Submit Method\n","assignment_id = \"00_pipeline_and_gradio\"\n","question_id = \"01_image_classification_using_hugging_faces_model\"\n","answer = str(result)  # Put your answer here\n","submit(student_id, name, assignment_id, answer, question_id, drive_link)"]},{"cell_type":"markdown","metadata":{"id":"5ZBnPIJdVlYG"},"source":["## Pipeline and Gradio"]},{"cell_type":"markdown","metadata":{"id":"B2wOiPqDiojo"},"source":["**Task 2: Image Classification using Hugging Face's Model and Gradio**\n","\n","In this second task, you will create a user-friendly interface using Gradio for your image classification pipeline that you created in Task 1. The difference with task 1 is, that in this task, you use **image files as input**, process them through the Hugging Face model, and display predictions output. The output displayed is **only the results with the highest `score`**.\n","\n","Here are the key steps that you might be able to follow:\n","\n","1. **Image Input:** Create a function to accept an image file as input. The image should be in a format that can be processed by the model.\n","2. **Model Loading and Prediction:** Load the model from Hugging Face's model hub and pass the image to the model to obtain the prediction. The model predicts the age of the person in the image.\n","3. **Gradio Interface:** Use Gradio to create a user-friendly interface for your application. The interface should allow users to upload an image file, and it should display the model's output in a clear and understandable manner.\n","4. **Interface Launch:** Launch the Gradio interface. Make sure that the interface is accessible and easy to use.\n","\n","## Submisssion\n","\n","![Upload colab](https://storage.googleapis.com/rg-ai-bootcamp/project-3-pipeline-and-gradio/upload-colab.png)\n","\n","You need to submit screenshot of your Gradio's app. In Google Colab you can just use the \"Folder\" sidebar and click the upload button. Make sure your screenshot match below requirements:\n","\n","- You should upload a person's image to that app\n","- The score should be included at the screenshot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsMSIbrwTKuB","executionInfo":{"status":"ok","timestamp":1707119309076,"user_tz":-420,"elapsed":1918,"user":{"displayName":"Citra Handan","userId":"02659360695432655610"}},"outputId":"3bfe78b8-731d-4ee3-d886-1b6d332cf951","colab":{"base_uri":"https://localhost:8080/","height":618}},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7861, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}],"source":["# @title #### 02. Image Classification using Hugging Face's Model and Gradio\n","\n","# Put your code here:\n","def age_classifier(image):\n","    im = Image.fromarray(image)\n","\n","    inputs = transforms(im, return_tensors='pt')\n","    output = model(**inputs)\n","\n","    proba = output.logits.softmax(1)\n","\n","    age = [\n","        '0-2',\n","        '3-9',\n","        '10-19',\n","        '20-29',\n","        '30-39',\n","        '40-49',\n","        '50-59',\n","        '60-69',\n","        'more than 70'\n","    ]\n","\n","    ind = proba.argmax(1)\n","\n","    return {\n","        'score': proba.tolist()[0][ind],\n","        'label': age[ind]\n","    }\n","\n","demo = gr.Interface(age_classifier, gr.Image(), \"json\")\n","demo.launch(debug=False, share=False)\n","# ---- End of your code ----"]},{"cell_type":"markdown","metadata":{"id":"iooYxZRr-222"},"source":["Example of Expected Output:\n","\n","![gradio-result](https://storage.googleapis.com/rg-ai-bootcamp/project-3-pipeline-and-gradio/gradio-result.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2tUQTyt-222","executionInfo":{"status":"ok","timestamp":1707119433171,"user_tz":-420,"elapsed":6664,"user":{"displayName":"Citra Handan","userId":"02659360695432655610"}},"outputId":"c6d5380d-12e3-48cd-ee77-8a00f001b375","colab":{"base_uri":"https://localhost:8080/","height":36}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Assignment successfully submitted'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["# Submit Method\n","question_id = \"02_image_classification_using_hugging_faces_model_and_gradio\"\n","submit_image(student_id, question_id, './submission.jpg')\n"]},{"cell_type":"markdown","metadata":{"id":"IIYX1tCa-223"},"source":["> Note: If your submission for Task-2 did not run (After you run it never changes from \"*\" to a number), stop the Code block that's running the Gradio app, then the submission will run. To stop the Code block, you can click on the Code block and then click the stop button."]}],"metadata":{"colab":{"provenance":[{"file_id":"1zu7V_8m_2c9pWynngCeUJJ5dMggu12j0","timestamp":1707110906529}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}